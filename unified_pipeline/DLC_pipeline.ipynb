{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC/ANIPOSE PIPELINE\n",
    "\n",
    "Automatically converts fly videos to estimated 3D coordinates using DeepLabCut and Anipose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "c:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\__init__.py:78: UserWarning: \n",
      "        As PyTorch is not installed, unsupervised identity learning will not be available.\n",
      "        Please run `pip install torch`, or ignore this warning.\n",
      "        \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dlc import analyze_new\n",
    "from preprocess import fix_point, remove_cols, df2hdf, gen_anipose_files\n",
    "import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 0: Configuration\n",
    "\n",
    "- Add filepath to DLC network config files (e.g `dlc_networks.yml`)\n",
    "- Add filepath to folder with experiment videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to the geontype folder containing videos\n",
    "videos = r\"C:\\Users\\bidayelab\\Documents\\SummerIntern\\RawData\\StochasticActivation\"\n",
    "videos = Path(videos)\n",
    "\n",
    "p_networks = Path(r'./common_files/dlc_networks.yml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Running DeepLabCut\n",
    "\n",
    "This will run on a directory with fly video files and generate DLC pose estimations, outputting to the same directory.\n",
    "\n",
    "##### Processing done:\n",
    "- DeepLabCut `analyze_videos`\n",
    "- DeepLabCut `filterpredictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_new(videos, p_networks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Preprocessing for anipose\n",
    "\n",
    "##### Processing done:\n",
    "- Fix points\n",
    "- Remove columns\n",
    "- Rename (GenotypeFly#-CamName)\n",
    "- Convert to .h5\n",
    "- Generate anipose file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing A-03292023203948-0000DLC_resnet101_camA_augmentedJan18shuffle1_500000_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [749.29818738 382.96283721   0.99999976 749.29367398 382.96472136\n",
      "   0.99999986 749.20514295 382.92177249   0.99999963 749.28162754\n",
      " 383.15254759   0.99999947 749.49860959 383.07010858   0.99999921]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[INFO] Processing B-03292023203954-0000DLC_resnet101_3cam_BEHSep16shuffle1_500000_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [8.09600878e+02 6.59742100e+02 1.53483012e-03 8.53145902e+02\n",
      " 6.23957933e+02 1.10206493e-03 8.87270861e+02 6.17763091e+02\n",
      " 9.51501710e-04 8.91842914e+02 6.17478425e+02 8.59824377e-04\n",
      " 8.92770287e+02 6.17954058e+02 7.96235220e-04]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] camName `B`, removing cols starting with `L-`\n",
      "[INFO] removed 240 columns starting with L-\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[INFO] Processing C-03292023204052-0000DLC_resnet101_camC_augmentedJan16shuffle1_500000_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [760.63057353 385.73903656   0.99676297 760.86519457 385.36110053\n",
      "   0.99675476 760.84795151 386.05777441   0.99674633 760.886554\n",
      " 386.06581695   0.99673248 760.80149904 386.03456819   0.99672523]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[INFO] Processing D-03292023203950-0000DLC_resnet101_camD_FS34_RN101Sep20shuffle1_500000_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [745.97266054 337.15169798   0.9999997  746.06129355 336.81841491\n",
      "   0.99999932 745.9046523  336.80786166   0.99999893 745.96083146\n",
      " 336.88683966   0.99999865 746.36253657 337.01282379   0.99999751]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[INFO] Processing E-03292023203952-0000DLC_resnet101_3cam_BEHSep16shuffle1_500000_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [7.73218956e+02 6.11985749e+02 3.84118517e-03 7.80084501e+02\n",
      " 6.21483172e+02 2.95060074e-03 7.82755673e+02 6.23867947e+02\n",
      " 2.40852506e-03 7.92249182e+02 6.25147096e+02 2.10320955e-03\n",
      " 7.92231257e+02 6.33263693e+02 1.90259046e-03]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] camName `E`, removing cols starting with `R-`\n",
      "[INFO] removed 240 columns starting with R-\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[INFO] Processing F-03292023204053-0000DLC_resnet101_camF_augmentedNov29shuffle1_500000_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [732.19444102 440.11494312   0.99999994 732.19138429 440.11665271\n",
      "   0.99999998 732.21172276 440.07162981   0.99999997 732.12083322\n",
      " 440.26083873   0.99999991 732.03335134 440.33479457   0.99999986]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[INFO] Processing H-03292023204055-0000DLC_resnet101_3cam_BEHSep16shuffle1_500000_filtered.csv\n",
      "[INFO] Running `Fix points` preprocessing...\n",
      "[INFO] Matching string TaG\n",
      "INFO value in TaG replaced with []\n",
      "[INFO] Matching string Notum\n",
      "INFO value in Notum replaced with [6.66542406e+02 6.98729312e+02 1.53363754e-03 6.70506101e+02\n",
      " 6.92975510e+02 1.10275297e-03 6.78480300e+02 7.06774863e+02\n",
      " 9.17278149e-04 6.75599814e+02 7.08839903e+02 8.05065989e-04\n",
      " 6.78662962e+02 7.15345052e+02 7.20056941e-04]\n",
      "[INFO] Matching string WH\n",
      "INFO value in WH replaced with []\n",
      "[INFO] Running `Remove cols` preprocessing...\n",
      "[INFO] Converting CSV to HDF...\n",
      "[INFO] Using root path \\\\mpfi.org\\public\\sb-lab\\BallSystem_RawData\n",
      "[ERROR] Incorrect root.\n",
      "Your root path does not match with the parent directory provided, please make sure that you provided the correct root.         \n",
      "The root should be the beginning of your parent directory path up to the folder containing raw data, e.g `\\mpfi.org\\public\\sb-lab\\BallSystem_RawData`\n",
      "\n",
      "[ERROR] Invalid calibration type or calibration type not specified in common_files\\calibration_target.yml\n",
      "Terminated due to error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bidayelab\\Documents\\SummerIntern\\Unified Pipeline\\unified_pipeline\\utils.py:36: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(csv, header=None)\n"
     ]
    }
   ],
   "source": [
    "# TODO: will probably handle all 3 below from a single directory\n",
    "error = False\n",
    "\n",
    "# find all the CSVs that DLC generated\n",
    "parent_dir = \"\"\n",
    "for p_csv in utils.get_csvs(videos):\n",
    "    parent_dir = p_csv.parent.parent.parent\n",
    "\n",
    "    # Pick current generated, filtered CSV \n",
    "    \n",
    "    # TODO: also check for cam name and model name\n",
    "    csv_name = p_csv.stem\n",
    "    if \"filtered\" not in csv_name:\n",
    "        continue\n",
    "\n",
    "    print(f\"[INFO] Processing {p_csv.name}\")\n",
    "    csv_df = utils.load_csv_as_df(p_csv)\n",
    "\n",
    "    # Fix points\n",
    "    print(\"[INFO] Running `Fix points` preprocessing...\")\n",
    "    col_names = ['TaG', 'Notum', 'WH']\n",
    "    n = -1 # Values will be replaced with the nth entry. To replace with the mean, use n=0\n",
    "    for name in col_names:\n",
    "        print(f\"[INFO] Matching string {name}\")\n",
    "        csv_df = fix_point(csv_df, name, n)\n",
    "\n",
    "    # Remove cols \n",
    "    print(\"[INFO] Running `Remove cols` preprocessing...\")\n",
    "    camName = p_csv.name[0]\n",
    "    start = ''\n",
    "    end = ''\n",
    "    if camName == 'B':\n",
    "        print(\"[INFO] camName `B`, removing cols starting with `L-`\")\n",
    "        start = 'L-' # Remove col if start of name matches string\n",
    "    if camName == 'E':\n",
    "        print(\"[INFO] camName `E`, removing cols starting with `R-`\")\n",
    "        start = 'R-' # Remove col if start of name matches string\n",
    "    csv_df = remove_cols(csv_df, start, end)\n",
    "\n",
    "    # Rename and convert to .h5 (saves to original directory)\n",
    "    print(\"[INFO] Converting CSV to HDF...\")\n",
    "    root = Path(r'C:\\Users\\bidayelab\\Documents\\SummerIntern\\RawData')\n",
    "    print(f\"[INFO] Using root path {root}\")\n",
    "    if df2hdf(csv_df, p_csv, root): # error occured\n",
    "        error = True\n",
    "\n",
    "\n",
    "# Generate anipose file structure\n",
    "p_calibration_target = Path(r\"./common_files/calibration_target.yml\") # calibration target config file \n",
    "p_calibration_timeline = Path(r\"./common_files/calib_timeline.yml\") # calibration timeline config file\n",
    "calibration_type = utils.get_calibration_type(p_calibration_target, parent_dir)\n",
    "if calibration_type == 'fly':\n",
    "    p_anipose_config = Path(r\"./common_files/config_fly.toml\") # anipose config file\n",
    "elif calibration_type == 'board':\n",
    "    p_anipose_config = Path(r\"./common_files/config_board.toml\") # anipose config file\n",
    "else:\n",
    "    print(f\"[ERROR] Invalid calibration type or calibration type not specified in {p_calibration_target}\")\n",
    "    error = True\n",
    "\n",
    "# check that all the files exist\n",
    "if not p_calibration_target.exists():\n",
    "    print(\"[ERROR] `calibration_target.yml` does not exist.\")\n",
    "    error = True\n",
    "if not p_calibration_timeline.exists():\n",
    "    print(\"[ERROR] `calib_timeline.yml` does not exist.\")\n",
    "    error = True\n",
    "\n",
    "if not error:\n",
    "    print(\"[INFO] Generating anipose files...\")\n",
    "    gen_anipose_files(parent_dir, p_networks, p_anipose_config, p_calibration_target, p_calibration_timeline)\n",
    "\n",
    "    print('Finished preprocessing...')\n",
    "else:\n",
    "    print(\"Terminated due to error\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
